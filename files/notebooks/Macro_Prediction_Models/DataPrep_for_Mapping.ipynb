{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPrep_for_Mapping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRIak8+6mOXGKZ7bIrV1vR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hdemma/hdemma.github.io/blob/master/Macro_Prediction_Models/DataPrep_for_Mapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSqqRPfj3rTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cfb98843-e21b-4194-a9f1-e7cc88825e78"
      },
      "source": [
        "!pip install geopandas\n",
        "!apt install libspatialindex-dev\n",
        "!pip install rtree"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a4/e66aafbefcbb717813bf3a355c8c4fc3ed04ea1dd7feb2920f2f4f868921/geopandas-0.8.1-py2.py3-none-any.whl (962kB)\n",
            "\r\u001b[K     |▍                               | 10kB 11.9MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.6MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 163kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 174kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 184kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 194kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 204kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 215kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 225kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 235kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 245kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 256kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 266kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 276kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 286kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 296kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 307kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 317kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 327kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 337kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 348kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 358kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 368kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 378kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 389kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 399kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 409kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 419kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 430kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 440kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 450kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 460kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 471kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 481kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 491kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 501kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 512kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 522kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 532kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 542kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 552kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 563kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 573kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 583kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 593kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 604kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 614kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 624kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 634kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 645kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 655kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 665kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 675kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 686kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 696kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 706kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 716kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 727kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 737kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 747kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 757kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 768kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 778kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 788kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 798kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 808kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 819kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 829kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 839kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 849kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 860kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 870kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 880kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 890kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 901kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 911kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 921kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 931kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 942kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 952kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 962kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 972kB 4.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.0.5)\n",
            "Collecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c3/071e080230ac4b6c64f1a2e2f9161c9737a2bc7b683d2c90b024825000c0/pyproj-2.6.1.post1-cp36-cp36m-manylinux2010_x86_64.whl (10.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9MB 24.6MB/s \n",
            "\u001b[?25hCollecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/20/4e63bc5c6e62df889297b382c3ccd4a7a488b00946aaaf81a118158c6f09/Fiona-1.8.13.post1-cp36-cp36m-manylinux1_x86_64.whl (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 255kB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (20.1.0)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pyproj, cligj, munch, click-plugins, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.5.0 fiona-1.8.13.post1 geopandas-0.8.1 munch-2.5.0 pyproj-2.6.1.post1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libspatialindex-c4v5 libspatialindex4v5\n",
            "The following NEW packages will be installed:\n",
            "  libspatialindex-c4v5 libspatialindex-dev libspatialindex4v5\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 555 kB of archives.\n",
            "After this operation, 3,308 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex4v5 amd64 1.8.5-5 [219 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex-c4v5 amd64 1.8.5-5 [51.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libspatialindex-dev amd64 1.8.5-5 [285 kB]\n",
            "Fetched 555 kB in 1s (471 kB/s)\n",
            "Selecting previously unselected package libspatialindex4v5:amd64.\n",
            "(Reading database ... 144579 files and directories currently installed.)\n",
            "Preparing to unpack .../libspatialindex4v5_1.8.5-5_amd64.deb ...\n",
            "Unpacking libspatialindex4v5:amd64 (1.8.5-5) ...\n",
            "Selecting previously unselected package libspatialindex-c4v5:amd64.\n",
            "Preparing to unpack .../libspatialindex-c4v5_1.8.5-5_amd64.deb ...\n",
            "Unpacking libspatialindex-c4v5:amd64 (1.8.5-5) ...\n",
            "Selecting previously unselected package libspatialindex-dev:amd64.\n",
            "Preparing to unpack .../libspatialindex-dev_1.8.5-5_amd64.deb ...\n",
            "Unpacking libspatialindex-dev:amd64 (1.8.5-5) ...\n",
            "Setting up libspatialindex4v5:amd64 (1.8.5-5) ...\n",
            "Setting up libspatialindex-c4v5:amd64 (1.8.5-5) ...\n",
            "Setting up libspatialindex-dev:amd64 (1.8.5-5) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting rtree\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/6f/f1e91001d5ad9fa9bed65875152f5a1c7955c5763168cae309546e6e9fda/Rtree-0.9.4.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from rtree) (49.6.0)\n",
            "Building wheels for collected packages: rtree\n",
            "  Building wheel for rtree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rtree: filename=Rtree-0.9.4-cp36-none-any.whl size=21767 sha256=bcaf7b499180cd63e3bec34707e0bc52802c54e7d2712bcc32e92e841a4235f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/20/c5/0004ef7acb96745ec99be960053902b0b414a2aa2dcad5834e\n",
            "Successfully built rtree\n",
            "Installing collected packages: rtree\n",
            "Successfully installed rtree-0.9.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIgwXkCQc3ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, time\n",
        "import geopandas as gpd\n",
        "import shutil\n",
        "from rtree import index\n",
        "from tqdm import tqdm\n",
        "from shapely.ops import cascaded_union\n",
        "from collections import defaultdict\n",
        "import folium\n",
        "from folium import plugins\n",
        "from shapely.geometry import *\n",
        "from IPython.display import display, HTML\n",
        "import math\n",
        "import random\n",
        "from  more_itertools import unique_everseen\n",
        "import geopy.distance\n",
        "from collections import Counter\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8xYSQf13l4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e81b9194-50fc-44e4-9c11-34aafb4a260f"
      },
      "source": [
        "#obtain the repository\n",
        "!git clone https://github.com/hdemma/hdemma.github.io.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hdemma.github.io'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 443 (delta 15), reused 0 (delta 0), pack-reused 399\u001b[K\n",
            "Receiving objects: 100% (443/443), 75.56 MiB | 24.04 MiB/s, done.\n",
            "Resolving deltas: 100% (173/173), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kb3fGgteFSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Vehicle_Type = 'Electric_Vehicles'\n",
        "Vehicle_ID = [751]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlLCYbGOdnCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28f5fdaa-f161-4d95-c019-3240100f69fd"
      },
      "source": [
        "%cd /content/hdemma.github.io/Dataset/OSM/\n",
        "OSM_FILE ='chattanooga_osm.shp'\n",
        "data = gpd.read_file(OSM_FILE)\n",
        "fclass = list(data['fclass'])\n",
        "\n",
        "CACHE_DIR = \"./cache\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/hdemma.github.io/Dataset/OSM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU-IjPxud1dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "osm_gdf = gpd.GeoDataFrame.from_file(OSM_FILE)\n",
        "if os.path.exists(CACHE_DIR):\n",
        "    shutil.rmtree(CACHE_DIR)\n",
        "os.makedirs(CACHE_DIR)\n",
        "\n",
        "spatial_index_file_name = \"{}/{}.spatial\".format(CACHE_DIR, \"osm_network\")\n",
        "spatial_tree = index.Index(spatial_index_file_name)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_9MiSUQd8iJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b602d49-ed5b-4b6b-e03f-7e5191cd239b"
      },
      "source": [
        "OSM_BUFFER = np.add(0.00015,0.00005)\n",
        "GEO_Shapes_DICT = {}\n",
        "osm_shps = []\n",
        "with tqdm(total=len(list(osm_gdf.iterrows()))) as pbar:\n",
        "    for i, gdf_row in osm_gdf.iterrows():\n",
        "        shape = gdf_row['geometry']\n",
        "        GEO_Shapes_DICT.update({gdf_row['osm_id']: gdf_row['geometry']})\n",
        "\n",
        "        shape = gdf_row['geometry'].buffer(OSM_BUFFER) # Buffer it if needed.\n",
        "        gdf_row['geometry'] = shape\n",
        "        spatial_tree.insert(int(gdf_row[\"osm_id\"]), shape.bounds, dict(gdf_row))\n",
        "        osm_shps.append(shape)\n",
        "        pbar.update(1)\n",
        "\n",
        "#plot_shps(osm_shps).save(\"osm_network.html\")\n",
        "\n",
        "bounds = spatial_tree.bounds\n",
        "bbox_shp = box(bounds[0],bounds[1], bounds[2], bounds[3])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 27807/27807 [00:25<00:00, 1078.40it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mHP-BXfd9r5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5e356db7-449f-4180-d84d-d1f5de5754e5"
      },
      "source": [
        "%cd /content/hdemma.github.io/Dataset/Electric_Vehicles/\n",
        "for v in Vehicle_ID:\n",
        "    Vehicle_Name = f'BYD_{v}'\n",
        "    print(f'Processing {Vehicle_Name}')\n",
        "    csv_url = 'file:///content/hdemma.github.io/Dataset/Electric_Vehicles/BYD_751_AfterEnergyCalculation.csv'\n",
        "\n",
        "    df = pd.read_csv('BYD_751_AfterEnergyCalculation.csv', low_memory=False)\n",
        "\n",
        "    Latitude = []\n",
        "    Longitude = []\n",
        "    SOC = []\n",
        "    Unix_Timestamp_ms = []\n",
        "    Time_US_Central = []\n",
        "\n",
        "    empty = []\n",
        "    F_Class = []\n",
        "    Bridge = []\n",
        "    Location_Index = []\n",
        "    OSM_ID_List = []\n",
        "    Street_Name = []\n",
        "    OSM_ID_List_Heuristic = []\n",
        "    OSM_DIST_LIST = []\n",
        "    Candidate_Segment = []\n",
        "\n",
        "    Avg_Forward_dist_LIST = []\n",
        "    Avg_Backward_dist_LIST = []\n",
        "    Max_Forward_dist_LIST = []\n",
        "    Max_Backward_dist_LIST = []\n",
        "    Min_Forward_dist_LIST = []\n",
        "    Min_Backward_dist_LIST = []\n",
        "\n",
        "    osm_geom_dict = {}\n",
        "\n",
        "\n",
        "    unix_Timestamp_ms = list(df['Unix Timestamp [ms]'])\n",
        "    time_US_Central = list(df['Time [US/Central]'])\n",
        "    soc = list(df['Computed_SoC_%'])\n",
        "    Lat = list(df['GPS - GPS position Latitude'])\n",
        "    Long = list(df['GPS - GPS position Longitude'])\n",
        "\n",
        "    \n",
        "    Road_Types_to_AVOID = [ 'path', 'pedestrian', 'footway', 'steps', 'cycleway','bridleway','unknown']\n",
        "\n",
        "\n",
        "    with tqdm(total=len(Lat)) as p:\n",
        "        for i in range(0,len(Lat)):\n",
        "            Lat[i] = float(Lat[i])\n",
        "            Long[i] = float(Long[i])\n",
        "            Location_Index.append(i)\n",
        "            SOC.append(soc[i])\n",
        "            Unix_Timestamp_ms.append(unix_Timestamp_ms[i])\n",
        "            Time_US_Central.append(time_US_Central[i])\n",
        "            if not math.isnan(Lat[i]):\n",
        "                osm_id_individual = {}\n",
        " \n",
        "                Point_Shape = Point(Long[i], Lat[i])\n",
        "                Latitude.append(Lat[i])\n",
        "                Longitude.append(Long[i])\n",
        "\n",
        "\n",
        "                #Temp for each location\n",
        "                for_heuristic =[]\n",
        "                osm = []\n",
        "                street_name = []\n",
        "                dist = []\n",
        "                fclass = []\n",
        "                bridge = []\n",
        "                Avg_dist = []\n",
        "                geometry = []\n",
        "\n",
        "                Avg_Forward = []\n",
        "                Avg_Backward = []\n",
        "                Max_Forward = []\n",
        "                Max_Backward = []\n",
        "                Min_Forward = []\n",
        "                Min_Backward = []\n",
        "\n",
        "                candidate = []\n",
        "\n",
        "                Point_buffered_Shape = Point(Long[i], Lat[i])  # .buffer(0.00001)\n",
        "\n",
        "                results = list(spatial_tree.intersection(Point_buffered_Shape.bounds, objects='raw'))\n",
        "                results = [street for street in results if street[\"geometry\"].intersection(Point_buffered_Shape)]\n",
        "                FinalSelection_Streets = [street for street in results if street[\"fclass\"] not in Road_Types_to_AVOID]\n",
        "\n",
        "                if len(FinalSelection_Streets)>=1:\n",
        "                    candidate_Number = 0\n",
        "                    for FS in FinalSelection_Streets:\n",
        "\n",
        "                        G = FS['geometry']\n",
        "                        candidate_Number+=1\n",
        "                        candidate.append(candidate_Number)\n",
        "\n",
        "                        \n",
        "\n",
        "                        osm.append(FS['osm_id'])\n",
        "                        street_name.append(FS['name'])\n",
        "                        geometry.append(FS['geometry'])\n",
        "\n",
        "                        distance_between_pts = G.exterior.distance(Point_Shape)\n",
        "                        dist.append(distance_between_pts)\n",
        "\n",
        "                        fclass.append(FS['fclass'])\n",
        "\n",
        "                        if FS['bridge'] == 'T':\n",
        "                            bridge.append(1)\n",
        "                        else:\n",
        "                            bridge.append(0)\n",
        "\n",
        "                        if i == 0:\n",
        "                            Avg_Forward.append(empty)\n",
        "                            Avg_Backward.append(empty)\n",
        "\n",
        "                            Max_Forward.append(empty)\n",
        "                            Max_Backward.append(empty)\n",
        "\n",
        "                            Min_Forward.append(empty)\n",
        "                            Min_Backward.append(empty)\n",
        "\n",
        "                        else:\n",
        "                            if i>0 and i< 15:\n",
        "                                tmp_forward = []\n",
        "                                tmp_backward = []\n",
        "                                for j in range(len(Lat[i:i + 14])):\n",
        "                                    Point_Shape = Point(Long[j], Lat[j])\n",
        "                                    distance_between_pts = G.exterior.distance(Point_Shape)\n",
        "\n",
        "                                    tmp_forward.append(distance_between_pts)\n",
        "\n",
        "                                Avg_Forward.append(sum(tmp_forward) / len(tmp_forward))\n",
        "                                Max_Forward.append(max(tmp_forward))\n",
        "                                Min_Forward.append(min(tmp_forward))\n",
        "\n",
        "                                Avg_Backward.append(empty)\n",
        "                                Max_Backward.append(empty)\n",
        "                                Min_Backward.append(empty)\n",
        "\n",
        "                            else:\n",
        "                                tmp_forward = []\n",
        "                                tmp_backward = []\n",
        "                                for j in range(len(Lat[i - 15: i])):\n",
        "                                    Point_Shape = Point(Long[j], Lat[j])\n",
        "                                    distance_between_pts = G.exterior.distance(Point_Shape)\n",
        "\n",
        "                                    tmp_backward.append(distance_between_pts)\n",
        "\n",
        "                                for j in range(len(Lat[i: i + 16])):\n",
        "                                    Point_Shape = Point(Long[j], Lat[j])\n",
        "                                    distance_between_pts = G.exterior.distance(Point_Shape)\n",
        "\n",
        "                                    tmp_forward.append(distance_between_pts)\n",
        "\n",
        "                                Avg_Forward.append(sum(tmp_forward)/len(tmp_forward))\n",
        "                                Avg_Backward.append(sum(tmp_backward)/len(tmp_backward))\n",
        "\n",
        "                                Max_Forward.append(max(tmp_forward))\n",
        "                                Max_Backward.append(max(tmp_backward))\n",
        "\n",
        "                                Min_Forward.append(min(tmp_forward))\n",
        "                                Min_Backward.append(min(tmp_backward))\n",
        "\n",
        "\n",
        "                osm_geom_dict= {osm_feature[\"osm_id\"]: osm_feature for osm_feature in FinalSelection_Streets}\n",
        "\n",
        "\n",
        "                if len(osm_geom_dict) != 0:\n",
        "                    for k, v in osm_geom_dict.items():\n",
        "                        osm_id_individual.update({k:v})\n",
        "                    for_heuristic.append(osm_id_individual) # add the value\n",
        "\n",
        "                    OSM_ID_List_Heuristic.append(for_heuristic)\n",
        "                    OSM_ID_List.append(osm)\n",
        "                    Street_Name.append(street_name)\n",
        "                    OSM_DIST_LIST.append(dist)\n",
        "                    F_Class.append(fclass)\n",
        "                    Bridge.append(bridge)\n",
        "\n",
        "                    Avg_Forward_dist_LIST.append(Avg_Forward)\n",
        "                    Avg_Backward_dist_LIST.append(Avg_Backward)\n",
        "\n",
        "                    Max_Forward_dist_LIST.append(Max_Forward)\n",
        "                    Max_Backward_dist_LIST.append(Max_Backward)\n",
        "\n",
        "                    Min_Forward_dist_LIST.append(Min_Forward)\n",
        "                    Min_Backward_dist_LIST.append(Min_Backward)\n",
        "                    Candidate_Segment.append(candidate)\n",
        "                else:\n",
        "                    OSM_ID_List.append(empty)\n",
        "                    OSM_ID_List_Heuristic.append(empty)\n",
        "                    Street_Name.append(empty)\n",
        "\n",
        "                    OSM_DIST_LIST.append(empty)\n",
        "                    Avg_Forward_dist_LIST.append(empty)\n",
        "                    Avg_Backward_dist_LIST.append(empty)\n",
        "\n",
        "                    Max_Forward_dist_LIST.append(empty)\n",
        "                    Max_Backward_dist_LIST.append(empty)\n",
        "\n",
        "                    Min_Forward_dist_LIST.append(empty)\n",
        "                    Min_Backward_dist_LIST.append(empty)\n",
        "\n",
        "                    F_Class.append(empty)\n",
        "                    Bridge.append(empty)\n",
        "\n",
        "                    Candidate_Segment.append(empty)\n",
        "\n",
        "            else:\n",
        "                Latitude.append(Lat[i])\n",
        "                Longitude.append(Long[i])\n",
        "\n",
        "                OSM_ID_List.append(empty)\n",
        "                OSM_ID_List_Heuristic.append(empty)\n",
        "                Street_Name.append(empty)\n",
        "\n",
        "                OSM_DIST_LIST.append(empty)\n",
        "                Avg_Forward_dist_LIST.append(empty)\n",
        "                Avg_Backward_dist_LIST.append(empty)\n",
        "\n",
        "                Max_Forward_dist_LIST.append(empty)\n",
        "                Max_Backward_dist_LIST.append(empty)\n",
        "\n",
        "                Min_Forward_dist_LIST.append(empty)\n",
        "                Min_Backward_dist_LIST.append(empty)\n",
        "                F_Class.append(empty)\n",
        "                Bridge.append(empty)\n",
        "                Candidate_Segment.append(empty)\n",
        "\n",
        "            p.update(1)\n",
        "\n",
        "    Final_value = []\n",
        "    Final_Count = []\n",
        "    print(len(OSM_ID_List_Heuristic))\n",
        "    with tqdm(total = len(Lat)) as pbar:\n",
        "        for i in range(0, len(Lat)):\n",
        "            if not math.isnan(Lat[i]):\n",
        "                Point_Shape = Point(Long[i], Lat[i])\n",
        "                test_shp = Point(Long[i], Lat[i])  # .buffer(0.002)\n",
        "\n",
        "                if len(OSM_ID_List_Heuristic[i]) != 0:\n",
        "                    count = []\n",
        "                    ID = []\n",
        "                    tmp_ID_result = []\n",
        "                    c = []\n",
        "                    for street in OSM_ID_List_Heuristic[i]:\n",
        "                        for key, value in street.items():\n",
        "                            ID.append(key)\n",
        "                            tmp_ID_result.append(0)\n",
        "                            for key2, value2 in value.items():  # Nested Dictionary\n",
        "                                if key2 == 'fclass':\n",
        "                                    if value2 == 'unclassified':\n",
        "                                        c.append(-2)\n",
        "                                    else:\n",
        "                                        c.append(0)\n",
        "                    for a in range(len(ID)):\n",
        "                        if i<15:\n",
        "                            for j in OSM_ID_List_Heuristic[:15]:\n",
        "                                if len(j) != 0:\n",
        "                                    for b in j:\n",
        "                                        for key, value in b.items():\n",
        "                                            if ID[a] == key:\n",
        "                                                c[a] += 1\n",
        "                                else:\n",
        "                                    continue\n",
        "\n",
        "                            count.append(c[a])\n",
        "                        else:\n",
        "                            for j in OSM_ID_List_Heuristic[i - 15: i + 16]:\n",
        "                                if len(j)!= 0:\n",
        "                                    for b in j:\n",
        "                                        for key, value in b.items():\n",
        "                                            if ID[a] == key:\n",
        "                                                c[a] += 1\n",
        "                                else:\n",
        "                                    continue\n",
        "\n",
        "                            count.append(c[a])\n",
        "\n",
        "                    m = count.index(max(count))\n",
        "\n",
        "                    tmp_ID_result[m] = 1\n",
        "                    Final_Count.append(count)\n",
        "                    Final_value.append(tmp_ID_result)\n",
        "\n",
        "\n",
        "                else:\n",
        "                    Final_value.append(empty)\n",
        "                    Final_Count.append(empty)\n",
        "\n",
        "\n",
        "            else:\n",
        "                Final_value.append(empty)\n",
        "                Final_Count.append(empty)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "\n",
        "    df = pd.DataFrame({\"Location_Index\":Location_Index,\n",
        "                       \"Unix_Timestamp_ms\":Unix_Timestamp_ms,\n",
        "                       \"Time_US_Central\":Time_US_Central,\n",
        "                       \"SOC\":SOC,\n",
        "                        \"Latitude\":Latitude,\n",
        "                       \"Longitude\": Longitude,\n",
        "                       \"Candidate\":Candidate_Segment,\n",
        "                       \"OSM_ID\":OSM_ID_List,\n",
        "                       \"Street_Name\":Street_Name,\n",
        "                       \"F_Class\":F_Class,\n",
        "                       \"Distance_from_location\":OSM_DIST_LIST,\n",
        "                       \"Average_Forward_Location\":Avg_Forward_dist_LIST,\n",
        "                       \"Average_Backward_Location\":Avg_Backward_dist_LIST,\n",
        "                       \"Max_Forward_Location\":Max_Forward_dist_LIST,\n",
        "                       \"Max_Backward_Location\": Max_Backward_dist_LIST,\n",
        "                       \"Min_Forward_Location\":Min_Forward_dist_LIST,\n",
        "                       \"Min_Backward_Location\": Min_Backward_dist_LIST,\n",
        "                       \"Bridge\":Bridge,\n",
        "                       \"Final_Count\":Final_Count,\n",
        "                       \"Final_Output\": Final_value\n",
        "                       })\n",
        "\n",
        "    csv = f\"{Vehicle_Name}_Data_for_Map_Matching.csv\"\n",
        "    df.to_csv(csv, index=False)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/hdemma.github.io/Dataset/Electric_Vehicles\n",
            "Processing BYD_751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82479/82479 [03:08<00:00, 437.74it/s]\n",
            "  2%|▏         | 1451/82479 [00:00<00:05, 14507.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "82479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82479/82479 [00:05<00:00, 14083.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCWeJIHf9zRS",
        "colab_type": "text"
      },
      "source": [
        "Data Splitting (One row for each candidate)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iF3od3R9-Fl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "567337fa-eacc-4758-dd4f-803b227d91a9"
      },
      "source": [
        "%cd /content/hdemma.github.io/Dataset/Electric_Vehicles/\n",
        "import tqdm\n",
        "for v in Vehicle_ID:\n",
        "    Vehicle_Name = f'BYD_{v}'\n",
        "\n",
        "    csv = f\"{Vehicle_Name}_Data_for_Map_Matching.csv\"\n",
        "    df = pd.read_csv(csv, low_memory=False)\n",
        "\n",
        "    print(df.columns)\n",
        "\n",
        "    Columns = ['Candidate', 'OSM_ID', 'Street_Name','F_Class',\n",
        "               'Distance_from_location', 'Average_Forward_Location',\n",
        "               'Average_Backward_Location', 'Max_Forward_Location',\n",
        "               'Max_Backward_Location', 'Min_Forward_Location',\n",
        "               'Min_Backward_Location', 'Bridge', 'Final_Count','Final_Output']\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col in Columns:\n",
        "            df[col] = df[col].apply(literal_eval)\n",
        "\n",
        "    unix_Timestamp_ms = list(df.Unix_Timestamp_ms)\n",
        "    time_US_Central = list(df.Time_US_Central)\n",
        "    location_index = list(df.Location_Index)\n",
        "    latitude = list(df.Latitude)\n",
        "    longitude = list(df.Longitude)\n",
        "    soc = df.SOC\n",
        "    candidate = list(df.Candidate)\n",
        "    fclass = list(df.F_Class)\n",
        "    osm_id = list(df.OSM_ID)\n",
        "    street_name = list(df.Street_Name)\n",
        "    distance_from_location = list(df.Distance_from_location)\n",
        "    average_forward_location = list(df.Average_Forward_Location)\n",
        "    average_backward_location = list(df.Average_Backward_Location)\n",
        "    max_forward_location = list(df.Max_Forward_Location)\n",
        "    max_backward_location = list(df.Max_Backward_Location)\n",
        "    min_forward_location = list(df.Min_Forward_Location)\n",
        "    min_backward_location = list(df.Min_Backward_Location)\n",
        "    bridge = list(df.Bridge)\n",
        "    final_count = list(df.Final_Count)\n",
        "    final_output = list(df.Final_Output)\n",
        "\n",
        "    Location_Index = []\n",
        "    Latitude = []\n",
        "    Longitude = []\n",
        "    SOC = []\n",
        "    Unix_Timestamp_ms = []\n",
        "    Time_US_Central = []\n",
        "    Candidate = []\n",
        "    F_Class = []\n",
        "    OSM_ID = []\n",
        "    Street_Name = []\n",
        "\n",
        "    Distance_from_location = []\n",
        "    Average_Forward_Location = []\n",
        "    Average_Backward_Location = []\n",
        "    Max_Forward_Location = []\n",
        "    Max_Backward_Location = []\n",
        "    Min_Forward_Location = []\n",
        "    Min_Backward_Location = []\n",
        "    Bridge = []\n",
        "    Final_Count = []\n",
        "    Final_Output = []\n",
        "\n",
        "\n",
        "    for i in tqdm.tqdm(range(len(df))):\n",
        "        for j in range(len(candidate[i])):\n",
        "            Latitude.append(latitude[i])\n",
        "            Longitude.append(longitude[i])\n",
        "            SOC.append(soc[i])\n",
        "            Unix_Timestamp_ms.append(unix_Timestamp_ms[i])\n",
        "            Time_US_Central.append(time_US_Central[i])\n",
        "            Location_Index.append(location_index[i])\n",
        "\n",
        "            if average_forward_location[i][j]==[]:\n",
        "                Average_Forward_Location.append('')\n",
        "            else:\n",
        "                Average_Forward_Location.append(average_forward_location[i][j])\n",
        "\n",
        "            if average_backward_location[i][j]== []:\n",
        "                Average_Backward_Location.append('')\n",
        "            else:\n",
        "                Average_Backward_Location.append(average_backward_location[i][j])\n",
        "\n",
        "            if max_forward_location[i][j]==[]:\n",
        "                Max_Forward_Location.append('')\n",
        "            else:\n",
        "                Max_Forward_Location.append(max_forward_location[i][j])\n",
        "\n",
        "            if max_backward_location[i][j]==[]:\n",
        "                Max_Backward_Location.append('')\n",
        "            else:\n",
        "                Max_Backward_Location.append(max_backward_location[i][j])\n",
        "\n",
        "            if min_forward_location[i][j]==[]:\n",
        "                Min_Forward_Location.append('')\n",
        "            else:\n",
        "                Min_Forward_Location.append(min_forward_location[i][j])\n",
        "\n",
        "            if min_backward_location[i][j]==[]:\n",
        "                Min_Backward_Location.append('')\n",
        "            else:\n",
        "                Min_Backward_Location.append(min_backward_location[i][j])\n",
        "            Candidate.append(candidate[i][j])\n",
        "\n",
        "            OSM_ID.append(osm_id[i][j])\n",
        "            F_Class.append(fclass[i][j])\n",
        "            Street_Name.append(street_name[i][j])\n",
        "\n",
        "            Distance_from_location.append(distance_from_location[i][j])\n",
        "\n",
        "            Bridge.append(bridge[i][j])\n",
        "            Final_Count.append(final_count[i][j])\n",
        "            Final_Output.append(final_output[i][j])\n",
        "\n",
        "\n",
        "    Road_Type = ['primary', 'primary_link',\n",
        "                 'secondary','secondary_link',\n",
        "                 'tertiary', 'tertiary_link',\n",
        "                  'trunk',\n",
        "                 'motorway','motorway_link',\n",
        "                 'service', 'residential',\n",
        "                 'track',\n",
        "                'unknown', 'unclassified']\n",
        "\n",
        "    primary=[]\n",
        "    primary_link=[]\n",
        "    secondary=[]\n",
        "    secondary_link=[]\n",
        "    tertiary=[]\n",
        "    tertiary_link=[]\n",
        "    trunk=[]\n",
        "    motorway=[]\n",
        "    motorway_link=[]\n",
        "    service=[]\n",
        "    residential=[]\n",
        "    track=[]\n",
        "    unknown = []\n",
        "    unclassified=[]\n",
        "\n",
        "\n",
        "    for i in range(len(F_Class)):\n",
        "        RT = []\n",
        "        for roadtype in range(len(Road_Type)):\n",
        "            if Road_Type[roadtype] == F_Class[i]:\n",
        "\n",
        "\n",
        "                RT.append(1)\n",
        "            else:\n",
        "                RT.append(0)\n",
        "        # print(RT)\n",
        "        for xx in range(len(RT)):\n",
        "            if xx == 0:\n",
        "                primary.append(RT[xx])\n",
        "            elif xx == 1:\n",
        "                primary_link.append(RT[xx])\n",
        "            elif xx == 2:\n",
        "                secondary.append(RT[xx])\n",
        "            elif xx == 3:\n",
        "                secondary_link.append(RT[xx])\n",
        "            elif xx == 4:\n",
        "                tertiary.append(RT[xx])\n",
        "            elif xx == 5:\n",
        "                tertiary_link.append(RT[xx])\n",
        "            elif xx == 6:\n",
        "                trunk.append(RT[xx])\n",
        "            elif xx == 7:\n",
        "                motorway.append(RT[xx])\n",
        "            elif xx == 8:\n",
        "                motorway_link.append(RT[xx])\n",
        "            elif xx == 9:\n",
        "                service.append(RT[xx])\n",
        "            elif xx == 10:\n",
        "                residential.append(RT[xx])\n",
        "            elif xx == 11:\n",
        "                track.append(RT[xx])\n",
        "            elif xx == 12:\n",
        "                unknown.append(RT[xx])\n",
        "            elif xx == 13:\n",
        "                unclassified.append(RT[xx])\n",
        "\n",
        "\n",
        "    df = pd.DataFrame({\"Location_Index\":Location_Index,\n",
        "                       \"Latitude\": Latitude,\n",
        "                       \"Longitude\": Longitude,\n",
        "                        \"Unix_Timestamp_ms\":Unix_Timestamp_ms,\n",
        "                       \"Time_US_Central\":Time_US_Central,\n",
        "                       \"SOC\":SOC,\n",
        "                       \"Candidate\": Candidate,\n",
        "                       \"OSM_ID\": OSM_ID,\n",
        "                       \"Street_Name\": Street_Name,\n",
        "                       \"F_Class\": F_Class,\n",
        "                       \"Distance_from_location\": Distance_from_location,\n",
        "                       \"Average_Forward_Location\": Average_Forward_Location,\n",
        "                       \"Average_Backward_Location\": Average_Backward_Location,\n",
        "                       \"Max_Forward_Location\": Max_Forward_Location,\n",
        "                       \"Max_Backward_Location\": Max_Backward_Location,\n",
        "                       \"Min_Forward_Location\": Min_Forward_Location,\n",
        "                       \"Min_Backward_Location\": Min_Backward_Location,\n",
        "                       \"Bridge\": Bridge,\n",
        "                       \"Primary\":primary,\n",
        "                       \"Primary_link\":primary_link,\n",
        "                       \"Secondary\":secondary,\n",
        "                       \"Secondary_link\":secondary_link,\n",
        "                       \"Tertiary\":tertiary,\n",
        "                       \"Tertiary_link\":tertiary_link,\n",
        "                       \"Trunk\":trunk,\n",
        "                       \"Motorway\":motorway,\n",
        "                       \"Motorway_link\":motorway_link,\n",
        "                       \"Service\":service,\n",
        "                       \"Residential\":residential,\n",
        "                       \"Track\":track,\n",
        "                       \"Unknown\":unknown,\n",
        "                       \"Unclassified\":unclassified,\n",
        "                       \"Final_Count\":Final_Count,\n",
        "                       \"Final_Output\": Final_Output\n",
        "                       })\n",
        "\n",
        "    csv = f\"{Vehicle_Name}_Data_for_Map_Matching_AfterSplit.csv\"\n",
        "    df.to_csv(csv, index=False)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/hdemma.github.io/Dataset/Electric_Vehicles\n",
            "Index(['Location_Index', 'Unix_Timestamp_ms', 'Time_US_Central', 'SOC',\n",
            "       'Latitude', 'Longitude', 'Candidate', 'OSM_ID', 'Street_Name',\n",
            "       'F_Class', 'Distance_from_location', 'Average_Forward_Location',\n",
            "       'Average_Backward_Location', 'Max_Forward_Location',\n",
            "       'Max_Backward_Location', 'Min_Forward_Location',\n",
            "       'Min_Backward_Location', 'Bridge', 'Final_Count', 'Final_Output'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82479/82479 [00:02<00:00, 29349.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}